{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Note: This is only applicable to Rhino. The principles of parallel computing are general and can be used to accelerate code on any system, but the implementations here are designed to interact with the scheduler used on the Computational Memory Lab cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parallel Computing with Dask\n",
    "\n",
    "<img src=\"https://hpc.llnl.gov/sites/default/files/styles/with_sidebar_1_up/public/nodesNetwork.gif?itok=TBqDQmx0\">\n",
    "\n",
    "A node is a like a computer within a much bigger computer!\n",
    "\n",
    "**CMLDask wrapper**:\n",
    "* See https://github.com/pennmem/cmldask for wrapper package created for convenience using Rhino + typical parallel setup for our analyses\n",
    "* Check out [Dask](https://docs.dask.org/en/stable/) and [Dask distributed](https://distributed.dask.org/en/stable/) for more documentation about the underlying implementation. In particular, we're using the [Futures API](https://docs.dask.org/en/stable/futures.html?highlight=futures) for managing parallel tasks and [dask-jobqueue](http://jobqueue.dask.org/en/latest/generated/dask_jobqueue.SGECluster.html#dask_jobqueue.SGECluster) to connect with the Sun Grid Engine (SGE) scheduler on rhino. \n",
    "* Note that this package is intended for convenience and will not accomodate very specific computational needs that demand complex parallel architectures. You will need to use dask directly and create your own `Client()` instances that are more closely tailored to your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic usage works as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmldask.CMLDask as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique port for ryan.colyer is 51391\n",
      "{'dashboard_address': ':51391'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN ryan.colyer@rhino2.psych.upenn.edu -L 7000:192.168.86.146:51391` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to http://localhost:7000 in your browser\n"
     ]
    }
   ],
   "source": [
    "import cmldask\n",
    "from dask.distributed import wait, as_completed, progress\n",
    "\n",
    "def squared(x):\n",
    "    return x**2\n",
    "\n",
    "client = da.new_dask_client(\"test_dask\", \"1GB\", max_n_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that you need to explicitly shut down this client (`client.shutdown()`) or shut down your jupyter kernel before running this cell again, or you might leave workers \"stranded\" without access to them (since that access is provided by the Client you would overwrite)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have options when setting up your Dask cluster/client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_dask_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Temporary wrapper for new_dask_client_sge for transition.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.conda/envs/environmentname/lib/python3.7/site-packages/cmldask/CMLDask.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "da.new_dask_client?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel computing tips\n",
    "\n",
    "* Jobs are still subject to memory limitations, so you may need to **break up large processes into smaller chunks.** For example, each job could correspond to analyzing one session, instead of one subject (this should be done, e.g., for all Morlet wavelet analyses). \n",
    "* It is often useful to save the output of each job in a dedicated directory, and sometimes useful to save intermediate values to aid in debugging or later nonparallel analyses. The Python \"os\" library can be helpful here. \n",
    "* **Be respectful!** There are only so many cores available to your classmates, the Kahana lab, and our collaborators across the country.\n",
    "* **Limit typical jobs to 5 cores or less**. Heavy usage means fewer resources for other users, and due to shared disk resources might actually slow down all jobs overall. Please ask for permission before using more.\n",
    "* You can always use the '**qdel**' command in Terminal, followed by your job number, to kill any of your old jobs that may be wasting rhino's resources. \n",
    "* Use the '**qstat**' command in Terminal to see cluster usage information for all users. The **'qstat | grep your_username'** command will just show the jobs associated with your username\n",
    "* Each rhino2 node has ~128 GB of memory and ~40 cores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Dask Futures Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bea4a2ea1643f1b6992460b67d9c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "def add(a, b):\n",
    "    sleep(np.random.randint(0, 10))\n",
    "    return a + b\n",
    "\n",
    "def error_add(a, b):\n",
    "    sleep(np.random.randint(0, 10))\n",
    "    if a % 2:\n",
    "        raise ValueError\n",
    "    return a + b\n",
    "\n",
    "futures = client.map(add, range(40), range(40))\n",
    "progress(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpriority\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mallow_other_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfifo_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'100 ms'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mactors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Map a function on a sequence of arguments\n",
       "\n",
       "Arguments can be normal objects or Futures\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "func : callable\n",
       "    Callable to be scheduled for execution. If ``func`` returns a coroutine, it\n",
       "    will be run on the main event loop of a worker. Otherwise ``func`` will be\n",
       "    run in a worker's task executor pool (see ``Worker.executors`` for more\n",
       "    information.)\n",
       "iterables : Iterables\n",
       "    List-like objects to map over.  They should have the same length.\n",
       "key : str, list\n",
       "    Prefix for task names if string.  Explicit names if list.\n",
       "workers : string or iterable of strings\n",
       "    A set of worker hostnames on which computations may be performed.\n",
       "    Leave empty to default to all workers (common case)\n",
       "retries : int (default to 0)\n",
       "    Number of allowed automatic retries if a task fails\n",
       "resources : dict (defaults to {})\n",
       "    Defines the `resources` each instance of this mapped task requires\n",
       "    on the worker; e.g. ``{'GPU': 2}``.\n",
       "    See :doc:`worker resources <resources>` for details on defining\n",
       "    resources.\n",
       "priority : Number\n",
       "    Optional prioritization of task.  Zero is default.\n",
       "    Higher priorities take precedence\n",
       "allow_other_workers : bool (defaults to False)\n",
       "    Used with `workers`. Indicates whether or not the computations\n",
       "    may be performed on workers that are not in the `workers` set(s).\n",
       "fifo_timeout : str timedelta (default '100ms')\n",
       "    Allowed amount of time between calls to consider the same priority\n",
       "actor : bool (default False)\n",
       "    Whether these tasks should exist on the worker as stateful actors.\n",
       "    See :doc:`actors` for additional details.\n",
       "actors : bool (default False)\n",
       "    Alias for `actor`\n",
       "pure : bool (defaults to True)\n",
       "    Whether or not the function is pure.  Set ``pure=False`` for\n",
       "    impure functions like ``np.random.random``.\n",
       "    See :ref:`pure functions` for more details.\n",
       "batch_size : int, optional\n",
       "    Submit tasks to the scheduler in batches of (at most)\n",
       "    ``batch_size``.\n",
       "    Larger batch sizes can be useful for very large ``iterables``,\n",
       "    as the cluster can start processing tasks while later ones are\n",
       "    submitted asynchronously.\n",
       "**kwargs : dict\n",
       "    Extra keyword arguments to send to the function.\n",
       "    Large values will be included explicitly in the task graph.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> L = client.map(func, sequence)  # doctest: +SKIP\n",
       "\n",
       "Returns\n",
       "-------\n",
       "List, iterator, or Queue of futures, depending on the type of the\n",
       "inputs.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Client.submit : Submit a single function\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.conda/envs/environmentname/lib/python3.7/site-packages/distributed/client.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client.map?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(error_add, range(40), range(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for all jobs to finish, check for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exception</th>\n",
       "      <th>traceback_obj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2f9bf3abe0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2f9bf8fa00&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2f9bff2a50&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac023280&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac048410&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac01e640&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac06b910&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac0197d0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac051320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac068aa0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac0b4730&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac0910a0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac0d93c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac047910&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac0dff50&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac0ba5f0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac100230&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac089190&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac0ea460&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ValueError()</td>\n",
       "      <td>&lt;traceback object at 0x2b2fac108410&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          exception                         traceback_obj\n",
       "param                                                    \n",
       "1      ValueError()  <traceback object at 0x2b2f9bf3abe0>\n",
       "3      ValueError()  <traceback object at 0x2b2f9bf8fa00>\n",
       "5      ValueError()  <traceback object at 0x2b2f9bff2a50>\n",
       "7      ValueError()  <traceback object at 0x2b2fac023280>\n",
       "9      ValueError()  <traceback object at 0x2b2fac048410>\n",
       "11     ValueError()  <traceback object at 0x2b2fac01e640>\n",
       "13     ValueError()  <traceback object at 0x2b2fac06b910>\n",
       "15     ValueError()  <traceback object at 0x2b2fac0197d0>\n",
       "17     ValueError()  <traceback object at 0x2b2fac051320>\n",
       "19     ValueError()  <traceback object at 0x2b2fac068aa0>\n",
       "21     ValueError()  <traceback object at 0x2b2fac0b4730>\n",
       "23     ValueError()  <traceback object at 0x2b2fac0910a0>\n",
       "25     ValueError()  <traceback object at 0x2b2fac0d93c0>\n",
       "27     ValueError()  <traceback object at 0x2b2fac047910>\n",
       "29     ValueError()  <traceback object at 0x2b2fac0dff50>\n",
       "31     ValueError()  <traceback object at 0x2b2fac0ba5f0>\n",
       "33     ValueError()  <traceback object at 0x2b2fac100230>\n",
       "35     ValueError()  <traceback object at 0x2b2fac089190>\n",
       "37     ValueError()  <traceback object at 0x2b2fac0ea460>\n",
       "39     ValueError()  <traceback object at 0x2b2fac108410>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wait(futures)\n",
    "errors = da.get_exceptions(futures, range(40))\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick out the index where you want to view the traceback message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-492535f77c2d>\", line 11, in error_add\n",
      "    raise ValueError\n"
     ]
    }
   ],
   "source": [
    "da.print_traceback(errors, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice gathering these doesn't work because there are errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-04978e95e583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/environmentname/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2150\u001b[0m                 \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m                 \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m                 \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2153\u001b[0m             )\n\u001b[1;32m   2154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/environmentname/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             return sync(\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             )\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/environmentname/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/environmentname/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/environmentname/lib/python3.7/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                         \u001b[0mexc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/environmentname/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   2007\u001b[0m                             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-492535f77c2d>\u001b[0m in \u001b[0;36merror_add\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client.gather(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, let's filter for successful ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_futures = da.filter_futures(futures)\n",
    "client.gather(good_futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT: Shutdown your client (or restart your kernel, which will do so automatically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Recommended Best Practices\n",
    "\n",
    "1. Watch your memory usage. Jobs that go over memory limits will error out. Delete unnecessary variables or overwrite variables to reduce memory overhead.\n",
    "2. Saving out **dimensionally reduced** intermediate outputs. \n",
    "    * Clusters can be unreliable and have outages, and jobs can get killed. Saving results from each job ensures that all results will not lost if a run dies partway through. \n",
    "    * You can write code to check if the results for a particular job have successfully returned and only recompute results for failed jobs.\n",
    "3. Avoid heavy disk usage by reading from and writing to a smaller number of medium to large-sized files rather than a large number of small files. The network/disk bandwidth on Rhino is a major bottleneck. If you use file IO (Input/Output, i.e., reading and writing to files) heavily, it will not only makes others' work slow, it can slow down your own analyses substantially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example code with the Pickle library, which allows for saving and loading (most) objects in Python\n",
    "# the pickle library is not recommended for long-term storage since it depends on having the same object \n",
    "# code/package versions available when loading an object that were present when the object was saved\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "arr = np.arange(1000)\n",
    "\n",
    "# save output\n",
    "with open('arr_test.pkl', 'wb') as f:\n",
    "    pickle.dump(arr, f)\n",
    "    \n",
    "# load output\n",
    "with open('arr_test.pkl', 'rb') as f:\n",
    "    arr_loaded = pickle.load(f)\n",
    "\n",
    "# confirm that loaded == saved\n",
    "np.all(arr == arr_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Settings():\n",
    "  '''settings = Settings()\n",
    "     settings.somelist = [1, 2, 3]\n",
    "     settings.importantstring = 'saveme'\n",
    "     settings.Save()\n",
    "\n",
    "     settings = Settings.Load()\n",
    "  '''\n",
    "  def __init__(self, **kwargs):\n",
    "    for k,v in kwargs.items():\n",
    "      self.__dict__[k] = v\n",
    "\n",
    "  def Save(self, filename='settings.pkl'):\n",
    "    import pickle\n",
    "    with open(filename, 'wb') as fw:\n",
    "      fw.write(pickle.dumps(self))\n",
    "\n",
    "  def Load(filename='settings.pkl'):\n",
    "    import pickle\n",
    "    return pickle.load(open(filename, 'rb'))\n",
    "\n",
    "  def __repr__(self):\n",
    "    return ('Settings(' +\n",
    "      ', '.join(str(k)+'='+repr(v) for k,v in self.__dict__.items()) +\n",
    "      ')')\n",
    "\n",
    "  def __str__(self):\n",
    "    return '\\n'.join(str(k)+': '+str(v) for k,v in self.__dict__.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment: FR1\n",
      "logbase: totalwords_\n",
      "sub_list: ['R1341T', 'R1391T', 'R1395M', 'R1467M']\n"
     ]
    }
   ],
   "source": [
    "settings = Settings()\n",
    "settings.experiment = 'FR1'\n",
    "settings.logbase = 'totalwords_'\n",
    "settings.sub_list = ['R1341T', 'R1391T', 'R1395M', 'R1467M']\n",
    "\n",
    "settings.Save('totalwords.pkl')\n",
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmldask.CMLDask as da\n",
    "from dask.distributed import wait, as_completed, progress\n",
    "from cmlreaders import CMLReader, get_data_index\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import traceback\n",
    "\n",
    "def TotalWords(sub):\n",
    "  logfile = f'{settings.logbase}{sub}.txt'\n",
    "  \n",
    "  df = get_data_index('all')\n",
    "  df = df[df['subject']==sub]\n",
    "  df = df[df['experiment']==settings.experiment]\n",
    "\n",
    "  total_words = 0\n",
    "  for df_sess in df.itertuples():\n",
    "    try:\n",
    "      df_sess = df_sess._asdict()\n",
    "      # Get parameters from the session DataFrame\n",
    "      exp = df_sess['experiment']\n",
    "      sess = df_sess['session']\n",
    "      # Prepare the reader\n",
    "      reader = CMLReader(sub, exp, sess, df_sess['montage'], df_sess['localization'])\n",
    "      # Get word events\n",
    "      evs = reader.load('task_events')\n",
    "      word_evs = evs[evs['type']=='WORD']\n",
    "      # Do our analysis!\n",
    "      total_words += len(word_evs)\n",
    "    except Exception as e:\n",
    "      # Log the exception to a subject-labeled filename,\n",
    "      # along with a label of subject, experiment, and session.\n",
    "      with open(logfile, 'a') as fw:\n",
    "        date = datetime.datetime.now().strftime('%F_%H-%M-%S')\n",
    "        fw.write(f'{date}: {sub}, {exp}, {sess}\\n' +\n",
    "                 ''.join(traceback.format_exception(type(e), e, e.__traceback__)))\n",
    "\n",
    "    \n",
    "  # Save the result.\n",
    "  np.save('wordcount_'+sub+'.npy', [total_words])\n",
    "  return total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique port for ryan.colyer is 51391\n",
      "{'dashboard_address': ':51391'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN ryan.colyer@rhino2.psych.upenn.edu -L 7000:192.168.86.146:51391` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to http://localhost:7000 in your browser\n"
     ]
    }
   ],
   "source": [
    "# Run in parallel\n",
    "client = da.new_dask_client(\"test_dask\", \"4GB\", max_n_jobs=5)\n",
    "futures = client.map(TotalWords, settings.sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoneAndNotDoneFutures(done={<Future: finished, type: int, key: TotalWords-8f4a8f526a8f4be34f6351d6d75c5253>, <Future: finished, type: int, key: TotalWords-c9d5e614d1c6afcba42acd23ab91dcb6>, <Future: finished, type: int, key: TotalWords-d068838fa6763922a00ab6017799e99e>, <Future: finished, type: int, key: TotalWords-1932628ac650f989bc6aa13997191bcb>}, not_done=set())"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait for results, check errors.\n",
    "wait(futures)\n",
    "#errors = da.get_exceptions(futures, range(40))\n",
    "#errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1260, 468, 936, 156]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_futures = da.filter_futures(futures)\n",
    "client.gather(good_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1341T had [1260] words\n",
      "R1391T had [468] words\n",
      "R1395M had [936] words\n",
      "R1467M had [156] words\n"
     ]
    }
   ],
   "source": [
    "settings = Settings.Load('totalwords.pkl')\n",
    "for sub in settings.sub_list:\n",
    "  total_words = np.load('wordcount_'+sub+'.npy')\n",
    "  print(f'{sub} had {total_words} words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happy parallel computing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Write a parallel function that returns the number of (bipolar) electrodes for every subject in the RAM example dataset (ignore localization and montage details). Run with 5 jobs and 1 core per job. This will require you to integrate the data loading procedures you learned earlier with the dask framework exhibited using the toy examples above**\n",
    "\n",
    "This example is purely for illustration and this task is likely not much faster with multiple nodes than with a single node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmentname",
   "language": "python",
   "name": "environmentname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
